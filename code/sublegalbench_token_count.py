# -*- coding: utf-8 -*-
"""subLegalBench_token_count.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MFDc-mT7kKptPvtoVL0Nk4uTQYIxK1fQ
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/DOUTORADO/TESE/my_git_repo/subLegalBench_experiment_1

!ls

from tqdm.auto import tqdm
import datasets
from tasks import TASKS, ISSUE_TASKS
from utils import generate_prompts
import os
import pandas as pd
from transformers import AutoTokenizer
from huggingface_hub import login

datasets.utils.logging.set_verbosity_error()

# Set up Hugging Face login
login(token="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")

# Initialize tokenizer
model_id = "meta-llama/Llama-2-7b-hf"
tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)

# Define function to calculate median
def calculate_median(numbers):
    sorted_numbers = sorted(numbers)
    n = len(sorted_numbers)
    mid = n // 2
    if n % 2 == 0:
        return (sorted_numbers[mid-1] + sorted_numbers[mid]) / 2
    return sorted_numbers[mid]

# Define function to process a single task
def process_task(task_name):
    legalbench_raw_path = "/content/drive/MyDrive/DOUTORADO/TESE/my_git_repo/subLegalBench_experiment_1/legalbench_data"
    legalbench_dataset_path = os.path.join(legalbench_raw_path, task_name)

    try:
        # Load test data
        test_df = pd.read_csv(os.path.join(legalbench_dataset_path, "test.tsv"), sep="\t")

        # Load prompt template
        with open(f"tasks/{task_name}/base_prompt.txt") as in_file:
            prompt_template = in_file.read()

        # Generate prompts
        prompt_dataset = generate_prompts(prompt_template=prompt_template, data_df=test_df)

        # Calculate token lengths
        tokenized_prompt_tokens = []
        for prompt in prompt_dataset:
            tokenized_prompt = tokenizer(prompt, return_tensors="pt")
            tokenized_prompt_tokens.append(tokenized_prompt['input_ids'].shape[1])

        # Calculate median
        median_tokens = calculate_median(tokenized_prompt_tokens)
        return median_tokens

    except Exception as e:
        print(f"Error processing task {task_name}: {str(e)}")
        return None

# Complete task list
all_tasks = [
    'learned_hands_benefits',
    'learned_hands_business',
    'learned_hands_consumer',
    'learned_hands_courts',
    'learned_hands_crime',
    'learned_hands_divorce',
    'learned_hands_domestic_violence',
    'learned_hands_education',
    'learned_hands_employment',
    'learned_hands_estates',
    'learned_hands_family',
    'learned_hands_health',
    'learned_hands_housing',
    'learned_hands_immigration',
    'learned_hands_torts',
    'learned_hands_traffic',
    'consumer_contracts_qa',
    'personal_jurisdiction',
    'ucc_v_common_law',
    'hearsay',
    'contract_nli_permissible_development_of_similar_information',
    'opp115_user_choice_control',
    'textualism_tool_plain',
    'textualism_tool_dictionaries',
    'function_of_decision_section',
    'oral_argument_question_purpose',
    'canada_tax_court_outcomes',
    'ssla_plaintiff',
    'cuad_governing_law',
    'cuad_insurance',
    'cuad_no-solicit_of_employees',
    'successor_liability',
    'cuad_affiliate_license-licensee',
    'cuad_affiliate_license-licensor',
    'cuad_change_of_control',
    'cuad_covenant_not_to_sue',
    'cuad_irrevocable_or_perpetual_license',
    'cuad_most_favored_nation',
    'cuad_no-solicit_of_customers',
    'cuad_non-compete',
    'cuad_non-disparagement',
    'cuad_price_restrictions',
    'cuad_third_party_beneficiary',
    'maud_specific_performance'
]

# Process all tasks and collect results
results = []
for task in tqdm(all_tasks):
    median_length = process_task(task)
    if median_length is not None:
        results.append({
            'task_name': task,
            'prompt_median_length': median_length,
            'tokenizer': model_id
        })

# Save results to CSV
results_df = pd.DataFrame(results)
results_df.to_csv('/content/drive/MyDrive/DOUTORADO/TESE/my_git_repo/subLegalBench_experiment_1/sublegalbench_prompt_length_stats.csv', index=False)
print("Results saved to prompt_length_stats.csv")
print(results_df)

